import os
from .common import melody_dataset_generator, load_melody_dataset, parallel_preload
import json

modulepath = os.path.dirname(os.path.abspath(__file__))
data_root = os.path.join(modulepath, "..", "data")

prefix = "maps"

def get_split():
    # For MAPS we use the train/validation/test split pregenerated by R. Kelz's code
    # See https://github.com/rainerkelz/framewise_2016
    with open(os.path.join(modulepath, "..", "data", "maps_kelz_split.json")) as f:
        # loads the track paths splits
        split = json.load(f)

    # filter out the parent directory path
    for s in split:
        track_ids = set()
        for track_path in split[s]:
            _, _, track_id = track_path.split("/")
            track_ids.add(track_id)
        split[s] = track_ids
    return split

def generator():
    dataset_audio_path = os.path.join(data_root, "MAPS", "*", "MUS")
    dataset_annot_path = os.path.join(data_root, "MAPS", "*", "MUS")

    return melody_dataset_generator(dataset_audio_path, dataset_annot_path, annot_suffix=".mid")

def dataset():
    return load_melody_dataset(prefix, generator())


def prepare(preload_fn, threads=None):
    split = get_split()

    def maps_split_generator(name):
        return filter(lambda t: t.track_id in split[name], generator())

    train_data = load_melody_dataset(prefix, maps_split_generator("train"))
    test_data = load_melody_dataset(prefix, maps_split_generator("test"))
    valid_data = load_melody_dataset(prefix, maps_split_generator("validation"))

    all_data = train_data+test_data+valid_data
    if threads == 1:
        for aa in all_data:
            preload_fn(aa)
    else:
        parallel_preload(preload_fn, all_data, threads=threads)
    
    # TODO: choose a better small validation
    small_validation_data = [
        valid_data[0].slice(0, 5),
        valid_data[1].slice(0, 5),
        valid_data[2].slice(0, 5),
    ]

    return train_data, test_data, valid_data, small_validation_data
